[
  {
    "objectID": "post.html",
    "href": "post.html",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "",
    "text": "AIS Doctor offers customized data scraping and analysis consulting services for young scholars ,Ph.D students, and small businesses. We have a dedicated team who will take care of your needs and help you with your project."
  },
  {
    "objectID": "post.html#ais-doctor",
    "href": "post.html#ais-doctor",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "",
    "text": "AIS Doctor offers customized data scraping and analysis consulting services for young scholars ,Ph.D students, and small businesses. We have a dedicated team who will take care of your needs and help you with your project."
  },
  {
    "objectID": "post.html#why-web-scraping",
    "href": "post.html#why-web-scraping",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "Why web scraping?",
    "text": "Why web scraping?\nDo you spend a significant amount of your budget for collecting data? If so, there might be a more efficient way to do that by leveraging r or Python."
  },
  {
    "objectID": "post.html#why-not-coping-pasting",
    "href": "post.html#why-not-coping-pasting",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "Why not coping & pasting?",
    "text": "Why not coping & pasting?\nFor data in simple format or smaller size, the simplest approach is to copy and paste."
  },
  {
    "objectID": "post.html#data-collection-using-public-apis",
    "href": "post.html#data-collection-using-public-apis",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "Data collection using public APIs",
    "text": "Data collection using public APIs\nWebsites like Yahoo finance, Google Trends, Reddit, and many others have public APIs that facilitate data collection using open source software and API keys."
  },
  {
    "objectID": "post.html#in-case-you-never-used-r-before",
    "href": "post.html#in-case-you-never-used-r-before",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "In case you never used R before",
    "text": "In case you never used R before\nR is a powerful tool for beginners looking to explore various tasks such as performing mathematical calculations, creating new calendars, and printing dates. With R, you can easily carry out basic math functions (like addition, subtraction, and more advanced operations), manage dates, and format them in different ways. By using functions like Sys.Date() for the current date, seq.Date() to create sequences of dates, or libraries like lubridate, you can manage time-related data effectively. R’s flexibility makes it accessible for learners to experiment and learn.\n\n1 + 1\n\n[1] 2\n\n\n\n## print a string\nstr &lt;- \"hello, my friends!\"\nprint(str)\n\n[1] \"hello, my friends!\"\n\n## show us the date for today\nformat(Sys.Date(), \"%c\")\n\n[1] \"Wed Oct  9 00:00:00 2024\"\n\n\n\n# install.packages(\"calendR\")\nlibrary(calendR)\n\n~~ Package calendR\nVisit https://r-coder.com/ for R tutorials ~~\n\ncalendR() # Defaults to current year"
  },
  {
    "objectID": "post.html#section",
    "href": "post.html#section",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "",
    "text": "Web Scraping - Workflow"
  },
  {
    "objectID": "post.html#scraping-top-finance-news-using-rvest-in-mini-seconds",
    "href": "post.html#scraping-top-finance-news-using-rvest-in-mini-seconds",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "Scraping top finance news using rvest in mini-seconds",
    "text": "Scraping top finance news using rvest in mini-seconds\nrvest is very similar to the Python library of beautifulsoup for Python users. Below is an example of collecting top news from Sina.com and display the top 6 results from the data.\nYou will need some basic knowledge of how html works."
  },
  {
    "objectID": "post.html#scraping-top-finance-news-using-rvest-in-mini-seconds-continued",
    "href": "post.html#scraping-top-finance-news-using-rvest-in-mini-seconds-continued",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "Scraping top finance news using rvest in mini-seconds (continued)",
    "text": "Scraping top finance news using rvest in mini-seconds (continued)\nIn this tutorial, we used rvest, the dplyr packages, and a few lines of syntax to scrape the top news."
  },
  {
    "objectID": "post.html#scraping-top-finance-news---loading-packages",
    "href": "post.html#scraping-top-finance-news---loading-packages",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "Scraping top finance news - loading packages",
    "text": "Scraping top finance news - loading packages\n\nlibrary(rvest)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union"
  },
  {
    "objectID": "post.html#scraping-top-finance-news-in-a-few-seconds-using-the-rvest-package",
    "href": "post.html#scraping-top-finance-news-in-a-few-seconds-using-the-rvest-package",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "Scraping top finance news in a few seconds using the rvest package",
    "text": "Scraping top finance news in a few seconds using the rvest package\nIn this example, we used R to scrape headlines from a finance website (Sina). First, I defined the URL of the site and read the webpage content using the read_html function. Then, I identified the specific HTML elements (headlines) I wanted by using a CSS selector (a.linkNewsTopBold). Finally, I extracted the text from these elements and displayed the first few headlines using the head function.\nIn R, we can use html_elements along with the CSS selector to identify html elements. Here, “a.linkNewsTopBold” is the html elements associated with the top news at finance.sina.com.cn. Please keep in mind that these elements may change over time.\nWe can then export the data to a text file and use it for other purposes. You may find the complete dataset here: https://github.com/utjimmyx/workshop/blob/main/sina_news.txt\n\n# Define the URL\nurl &lt;- \"https://finance.sina.com.cn/\"\n# Read the webpage content\nwebpage &lt;- read_html(url)\n# identify the html elements using the css selector first\nheadlines &lt;- webpage %&gt;%\n  html_nodes(\"a.linkNewsTopBold\") %&gt;% # adjust the selector based on the HTML structure\n  html_text()\nhead(headlines)\n\n[1] \"节后经济形势座谈会 哪些信息值得关注\"               \n[2] \"指数巨量回调 两市成交额超2.9万亿元\"                \n[3] \"直播中国牛市!\"                                     \n[4] \"国家发改委:出台有力有效系列举措 努力提振资本市场\"  \n[5] \"紧扣\\\"两强两严\\\"目标 Q3对291起违法违规采取监管措施\"\n[6] \"我国计划2026年底基本建成国家数据标准体系\""
  },
  {
    "objectID": "post.html#what-is-next",
    "href": "post.html#what-is-next",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "What is next?",
    "text": "What is next?\nBy leveraging the power of R and open source libraries, you can analyze text data and examine the sentiments and the meaning of textual data in real time. You can also analyze the sentiments of news articles by scraping articles in batch."
  },
  {
    "objectID": "post.html#what-else-can-i-do-with-r",
    "href": "post.html#what-else-can-i-do-with-r",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "What else can I do with R?",
    "text": "What else can I do with R?\nWell, R offers you encough flexibility when it comes to App development as well. For instance, you can leverage R and R Shiny (an advanced web API framework) for user-friendly Apps.\nBelow is a screenshot of an App that lets you scrape LinkedIn jobs and was built using R and R Shiny by us.\n You can visit the App available here: here:https://utjimmyx.shinyapps.io/jobs/\nNote: refresh if the server is busy."
  },
  {
    "objectID": "post.html#feedback",
    "href": "post.html#feedback",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "Feedback",
    "text": "Feedback\nAt AIS Doctor, we offer customized services in data scraping and analysis. We thank you for your time and effort. Let us know your data collection needs and will help you!"
  },
  {
    "objectID": "post.html#references",
    "href": "post.html#references",
    "title": "Web Scraping - Efficient Web Data Collection using R and rvest",
    "section": "References",
    "text": "References\ncalendR. https://github.com/R-CoderDotCom/calendR\nWeb scraping using R. https://r4ds.hadley.nz/webscraping\nQuarto - Using R - Overview. https://quarto.org/docs/computations/r.html"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "What does AIS Doctor offer?\nAIS Doctor offers customized data scraping and analysis consulting services for young scholars, Ph.D. students, and small businesses. We have a dedicated team consisted of data scientists, professors in data analytics and information system. We will take care of your needs and help you move forward with your project.\nBrowse our sample projects for more info.\n\n\nSpecializations include:\n\nData Scraping/Crawling using R or Python\nData Analysis & modeling\nStatistical modeling\nShort courses and workshops for business professionals\nIndependent research/analysis\n\n\n\n\n \n\nBackground\n\nExtensive training and experience in analytics research, teaching, and outreach\nAuthors/co-authors of over 40 peer-reviewed articles focusing on applied consulting research\n\n\n\nWant to get started on a project?\nSchedule a 30-minute call with AIS Doctor so we can learn more about your project."
  }
]